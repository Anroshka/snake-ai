# Snake AI with Deep Q-Learning ğŸ

An advanced implementation of a Snake game AI that learns through Deep Q-Learning, featuring real-time visualization, multi-agent support, and performance optimizations.

## ğŸ“š Table of Contents

1. [ğŸš€ Key Features](#-key-features)
2. [ğŸ› ï¸ Technical Specifications](#ï¸-technical-specifications)
3. [ğŸ“Š Real-time Visualization](#-real-time-visualization)
4. [ğŸš€ Installation](#-installation)
5. [ğŸ’» Usage](#-usage)
6. [âš™ï¸ Performance Features](#-performance-features)
7. [ğŸ”„ Automatic Saving](#-automatic-saving)
8. [ğŸ® Controls](#-controls)
9. [ğŸ“ˆ Training Graphs](#-training-graphs)
10. [ğŸ¯ Latest Improvements](#-latest-improvements)
11. [ğŸš€ Next Steps](#-next-steps)
12. [ğŸ“ Requirements](#-requirements)
13. [ğŸ”§ Configuration](#-configuration)
14. [ğŸ“š Project Structure](#-project-structure)
15. [ğŸ¤ Contributing](#-contributing)
16. [ğŸ“„ License](#-license)

## ğŸš€ Key Features

- ğŸ§  Deep Q-Network with Priority Experience Replay (PER)
- ğŸ® Real-time game visualization with informative HUD
- ğŸ“Š Multi-agent support (2-6 snakes training simultaneously)
- ğŸ“Š Live training statistics and performance graphs
- ğŸ”„ Automatic checkpointing and model saving
- âš¡ CUDA-accelerated training with AMP
- ğŸ“ˆ Adaptive learning parameters
- ğŸ¯ Enhanced exploration/exploitation balance
- ğŸ¤– Interactive agent count configuration

## ğŸ› ï¸ Technical Specifications

| Feature          | Description                                      |
|------------------|--------------------------------------------------|
| **Framework**    | PyTorch with CUDA support                        |
| **Visualization**| Pygame, Matplotlib                               |
| **Neural Network**| Input Layer: 17 neurons (enhanced state)        |
|                  | Hidden Layer: 512 neurons                        |
|                  | Output Layer: 4 actions (movement directions)    |
| **Training Parameters**| Learning Rate: 0.0005                      |
|                  | Gamma: 0.99                                      |
|                  | Initial Epsilon: 1.0                             |
|                  | Epsilon Decay: 0.997                             |
|                  | Memory Size: 100,000                             |
|                  | Batch Size: 64                                   |

## ğŸ“Š Real-time Visualization

- Individual scores for each snake
- Best score achieved
- Rolling average (last 100 games)
- Exploration rate (Epsilon)
- Samples collected
- Training performance (FPS)
- Loss function evolution
- Score distribution histogram
- Multi-agent interaction visualization

## ğŸš€ Installation

1. Clone the repository
```bash
git clone https://github.com/Anroshka/snake-ai.git
cd snake-ai
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

For CUDA support (recommended):
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

## ğŸ’» Usage

Start training:
```bash
python train_multi.py
```

You'll be prompted to enter the number of snakes (2-6 recommended) for training.

## âš™ï¸ Performance Features

- Multi-agent learning environment
- Multi-threaded processing
- Automatic device selection (GPU/CPU)
- Optimized rendering with FPS control
- Gradient clipping for stability
- Automatic Mixed Precision (AMP)
- Priority Experience Replay
- Efficient memory management
- Advanced reward system

## ğŸ”„ Automatic Saving

- Best model preservation
- Checkpoints every 10 episodes
- Training statistics graphs
- Performance metrics tracking
- Individual agent models saving

## ğŸ® Controls

- ESC: Exit training
- Automatic gameplay during training
- Visualization every 10 episodes
- Training stats display
- Interactive agent count selection

## ğŸ“ˆ Training Graphs

- Multi-agent learning progress
- Loss function
- Epsilon decay
- Score distribution
- Moving averages
- Agent interaction patterns

## ğŸ¯ Latest Improvements

- Added multi-agent support (2-6 snakes)
- Enhanced visualization with semi-transparent HUD
- Stabilized FPS for better visualization
- Minimum samples threshold for training start
- Improved error handling and stability
- Better memory management
- Adaptive learning parameters
- Interactive configuration system

## ğŸš€ Next Steps

- [ ] Add competitive and cooperative training modes
- [ ] Implement agent specialization
- [ ] Optimize multi-agent interactions
- [ ] Develop adaptive learning rate scheduling
- [ ] Explore different state representations
- [ ] Add agent personality traits

## ğŸ“ Requirements

- Python 3.10+
- CUDA-capable GPU (recommended)
- PyTorch 2.0+
- Pygame 2.4.0
- Matplotlib for visualization

## ğŸ”§ Configuration

All training parameters can be adjusted in `train_multi.py`:
- Number of agents (2-6)
- Episode count
- Memory size
- Batch size
- Learning rate
- Epsilon decay
- Visualization frequency
- Reward system parameters

## ğŸ“š Project Structure

- `game.py`: Snake game environment with multi-agent support
- `model.py`: DQN implementation with PER
- `train_multi.py`: Multi-agent training loop and visualization
- `models/`: Saved models and checkpoints

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
